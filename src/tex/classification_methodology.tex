\chapter{Classification and Methodology}
\label{ch:Classification and Methodology}
%\section{Eins - Eins}
%\subsection{Eins - Eins - Eins}

% Die Logos sind veraltet und duerfen zurzeit nicht verwendet werden!
% Auf Seite \pageref{Logo} in Abbildung \ref{Logo} befindet sich das SE Logo.
The classification of feature location techniques is very important, because of the different special demands of some classes of techniques and their assumptions they have towards special parts of the system or code.
The first big distinction is the difference of dynamic and static techniques. \newline
\\
\underline{dynamic}:\newline
Dynamic approaches collect information about the program at runtime. They do so by using program dependency analysis, information retrieval, latent semantic indexing (~\ref{ch:lsi} or the term frequency - inverse document frequency{~\ref{ch_tf-idf}, which only consider the methods and classes, which are involved during the current execution of the program. This is a big advantage, because by knowing that looking for a feature knowing roughly the part of the program where it could be used the user is able to steer the program into the direction. In our example the \emph{automaticSaveFile}-function wouldn't be in the main-menu or the settings, but is more likely to be involved if the user creates a mind map and waits till the \emph{automaticSaveFile}-function is triggered. But that advantage has also it's flipside. By only analyzing the involved parts of the program the whole information retrieval is based on the input the program gets and has to generalize from that, which may not be the right thing to do. Also collecting information on test-cases can only derive \emph{functional} requirements, but isn't able to derive non-functional requirements. In general the dynamic approaches under approximate.\newline
\underline{static}:\newline
Static approaches don't need the program to be executed. They collect information directly out of the source, which has  one big disadvantage. A static approach would look at every single part of the code to derive information about the feature, the user want's to locate, which can be very costly. Imagine a program which is very very complex and big and the user wants to locate a very small special feature which is contained in very little of the code for example in only 0.01\% . The static approach will look through the whole 100\% of code, of which 99.99\% are not related to the feature. The big advantage of the static approach is that the information it reveals are safe, which means it doesn't has to generalize out of a case but can validate on the whole information. This results in the ability to derive functional and non-functional requirements. This whole information can on the other side lead again to problems. Knowing every little detail can lead to situations in which the information's are undecidable in the matter of affiliation to the feature. So the technique has to approximate a solution, which may be to imprecise. In general the static approaches over approximate. \newline
\\
The techniques can also be splitted within the \emph{static}/\emph{dynamic}-groups due to the form of output the methods give. \newline \\
\underline{plain}:\newline
The plain-output techniques present an unsorted list of artifacts, which are considered by the technique to be relevant to the feature. They leave the interpreting of the output to the user. \newline
\underline{guided}:\newline
The guided-output techniques present the collected artifacts in a special arrangement to build an interpretation, like ordering the artifacts based on the relevance it is considered to have. Also often a so called \emph{Program Dependency Graph} is given to not only show relevant artifacts, but also give a dependency of these artifacts. This topic is further explained in "Case Study of Feature Location Using Dependence Graph" by K. Chen and V. Rajlich \cite{chen2000case}.\newline

Also the different techniques make assumptions. For example the in chapter~\ref{ch:lsi} mentioned \emph{Latent Semantic Indexing} does the assumption that the classes and methods of the code are named like the function they implement. The same technique can be useful on one code fragment, which fits the assumptions, but completely useless on an other one, which doesn't fulfill the assumptions. \cite{rubin2013survey} \cite{dit2013feature} \newline

An other file in which the different methods can be distinguished is the amount of user interaction within the process of locating a feature. While some methods can derive features and corresponding artifacts with almost only the name of the wanted feature, others need very much interaction to derive these artifacts. The result depends on the underlying code, the feature and also on the assumptions they make towards the code.\newline
%\clearpage